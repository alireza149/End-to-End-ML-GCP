{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUCKET_NAME = \"qwiklabs-gcp-01-c2d37df448e7\" #@param {type:\"string\"}\n",
    "REGION = \"us-east1\" #@param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating gs://qwiklabs-gcp-01-c2d37df448e7/...\n"
     ]
    }
   ],
   "source": [
    "# Creating a bucket\n",
    "\n",
    "! gsutil mb -l $REGION gs://$BUCKET_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test access to the bucket\n",
    "\n",
    "! gsutil ls -al gs://$BUCKET_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create SQL query using natality data after the year 2000\n",
    "query = \"\"\"\n",
    "SELECT\n",
    "  weight_pounds,\n",
    "  is_male,\n",
    "  mother_age,\n",
    "  plurality,\n",
    "  gestation_weeks,\n",
    "  FARM_FINGERPRINT(CONCAT(CAST(YEAR AS STRING), CAST(month AS STRING))) AS hashmonth\n",
    "FROM\n",
    "  publicdata.samples.natality\n",
    "WHERE year > 2000\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>weight_pounds</th>\n",
       "      <th>is_male</th>\n",
       "      <th>mother_age</th>\n",
       "      <th>plurality</th>\n",
       "      <th>gestation_weeks</th>\n",
       "      <th>hashmonth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.686620</td>\n",
       "      <td>True</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>43</td>\n",
       "      <td>8904940584331855459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.360828</td>\n",
       "      <td>True</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>1088037545023002395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.437091</td>\n",
       "      <td>False</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>5896567601480310696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.124442</td>\n",
       "      <td>False</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>-6244544205302024223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.125340</td>\n",
       "      <td>False</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>-8029892925374153452</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   weight_pounds  is_male  mother_age  plurality  gestation_weeks  \\\n",
       "0       6.686620     True          18          1               43   \n",
       "1       9.360828     True          32          1               41   \n",
       "2       8.437091    False          30          1               39   \n",
       "3       6.124442    False          24          1               40   \n",
       "4       7.125340    False          26          1               41   \n",
       "\n",
       "             hashmonth  \n",
       "0  8904940584331855459  \n",
       "1  1088037545023002395  \n",
       "2  5896567601480310696  \n",
       "3 -6244544205302024223  \n",
       "4 -8029892925374153452  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Call BigQuery and examine in dataframe\n",
    "from google.cloud import bigquery\n",
    "df = bigquery.Client().query(query + \" LIMIT 100\").to_dataframe()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "# Get one hot encoding of columns B\n",
    "one_hot = pd.get_dummies(df['is_male'])\n",
    "# Drop column B as it is now encoded\n",
    "df = df.drop('is_male',axis = 1)\n",
    "# Join the encoded df\n",
    "df = df.join(one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>weight_pounds</th>\n",
       "      <th>mother_age</th>\n",
       "      <th>plurality</th>\n",
       "      <th>gestation_weeks</th>\n",
       "      <th>hashmonth</th>\n",
       "      <th>False</th>\n",
       "      <th>True</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.063611</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>37.0</td>\n",
       "      <td>7108882242435606404</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.687028</td>\n",
       "      <td>30</td>\n",
       "      <td>3</td>\n",
       "      <td>33.0</td>\n",
       "      <td>-7170969733900686954</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.561856</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>39.0</td>\n",
       "      <td>6392072535155213407</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.561856</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>37.0</td>\n",
       "      <td>-2126480030009879160</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.312733</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>40.0</td>\n",
       "      <td>3408502330831153141</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   weight_pounds  mother_age  plurality  gestation_weeks            hashmonth  \\\n",
       "0       7.063611          32          1             37.0  7108882242435606404   \n",
       "1       4.687028          30          3             33.0 -7170969733900686954   \n",
       "2       7.561856          20          1             39.0  6392072535155213407   \n",
       "3       7.561856          31          1             37.0 -2126480030009879160   \n",
       "4       7.312733          32          1             40.0  3408502330831153141   \n",
       "\n",
       "   False  True  \n",
       "0      0     1  \n",
       "1      0     1  \n",
       "2      0     1  \n",
       "3      0     1  \n",
       "4      0     1  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting preprocess.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile preprocess.py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "class MySimpleScaler(object):\n",
    " \n",
    "\n",
    " def preprocess(self, data):\n",
    "    data = data[data.weight_pounds  > 0]\n",
    "    data = data[data.mother_age  > 0]\n",
    "    data = data[data.plurality > 0]\n",
    "    data = data[data.gestation_weeks > 0]\n",
    "    print(data.shape)\n",
    "\n",
    "    x_cols = ['mother_age', 'plurality', 'gestation_weeks', True,False]\n",
    "    # Get one hot encoding of columns B\n",
    "    one_hot = pd.get_dummies(data['is_male'])\n",
    "    # Drop column B as it is now encoded\n",
    "    data = data.drop('is_male',axis = 1)\n",
    "    # Join the encoded df\n",
    "    data = data.join(one_hot)\n",
    "\n",
    "\n",
    "    return data[x_cols],data['weight_pounds']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = df[df.mother_age  > 0]\n",
    "df = df[df.plurality > 0]\n",
    "df = df[df.gestation_weeks > 0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     6.426475\n",
       "1     6.181762\n",
       "2     8.750147\n",
       "3     6.812284\n",
       "4     7.500126\n",
       "        ...   \n",
       "95    7.837433\n",
       "96    7.561856\n",
       "97    5.875319\n",
       "98    5.577695\n",
       "99    8.811877\n",
       "Name: weight_pounds, Length: 100, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['weight_pounds']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=2,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "           oob_score=False, random_state=0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "from preprocess import MySimpleScaler\n",
    "\n",
    "\n",
    "scaler = MySimpleScaler()\n",
    "X,y = scaler.preprocess(df)\n",
    "#print(data_new)\n",
    "\n",
    "model = RandomForestRegressor(max_depth=2, random_state=0)\n",
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.21235293 0.07755402 0.66532064 0.02075033 0.02402208]\n",
      "0.2951073163844412\n"
     ]
    }
   ],
   "source": [
    "print(model.feature_importances_)\n",
    "print(model.score(X,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 5)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(model, 'model.joblib')\n",
    "with open ('preprocessor.pkl', 'wb') as f:\n",
    "  pickle.dump(scaler, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Deploying a custom prediction routine\n",
    "To deploy a custom prediction routine to serve predictions from your trained model, do the following:\n",
    "\n",
    "Create a custom predictor to handle requests\n",
    "Package your predictor and your preprocessing module\n",
    "Upload your model artifacts and your custom code to Cloud Storage\n",
    "Deploy your custom prediction routine to AI Platform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing predictor.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile predictor.py\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "class MyPredictor(object):\n",
    "  def __init__(self, model, preprocessor):\n",
    "    self._model = model\n",
    "    self._preprocessor = preprocessor\n",
    "    #self._class_names = load_iris().target_names\n",
    "\n",
    "  def predict(self, instances, **kwargs):\n",
    "    inputs = np.asarray(instances)\n",
    "    preprocessed_inputs = self._preprocessor.preprocess(inputs)\n",
    "\n",
    "  @classmethod\n",
    "  def from_path(cls, model_dir):\n",
    "    model_path = os.path.join(model_dir, 'model.joblib')\n",
    "    model = joblib.load(model_path)\n",
    "\n",
    "    preprocessor_path = os.path.join(model_dir, 'preprocessor.pkl')\n",
    "    with open(preprocessor_path, 'rb') as f:\n",
    "      preprocessor = pickle.load(f)\n",
    "\n",
    "    return cls(model, preprocessor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing setup.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile setup.py\n",
    "from setuptools import setup\n",
    "\n",
    "setup(\n",
    "    name='my_custom_code',\n",
    "    version='0.1',\n",
    "    scripts=['predictor.py', 'preprocess.py'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running sdist\n",
      "running egg_info\n",
      "creating my_custom_code.egg-info\n",
      "writing my_custom_code.egg-info/PKG-INFO\n",
      "writing top-level names to my_custom_code.egg-info/top_level.txt\n",
      "writing dependency_links to my_custom_code.egg-info/dependency_links.txt\n",
      "writing manifest file 'my_custom_code.egg-info/SOURCES.txt'\n",
      "reading manifest file 'my_custom_code.egg-info/SOURCES.txt'\n",
      "writing manifest file 'my_custom_code.egg-info/SOURCES.txt'\n",
      "running check\n",
      "warning: check: missing required meta-data: url\n",
      "\n",
      "warning: check: missing meta-data: either (author and author_email) or (maintainer and maintainer_email) must be supplied\n",
      "\n",
      "creating my_custom_code-0.1\n",
      "creating my_custom_code-0.1/my_custom_code.egg-info\n",
      "copying files to my_custom_code-0.1...\n",
      "copying README.md -> my_custom_code-0.1\n",
      "copying predictor.py -> my_custom_code-0.1\n",
      "copying preprocess.py -> my_custom_code-0.1\n",
      "copying setup.py -> my_custom_code-0.1\n",
      "copying my_custom_code.egg-info/PKG-INFO -> my_custom_code-0.1/my_custom_code.egg-info\n",
      "copying my_custom_code.egg-info/SOURCES.txt -> my_custom_code-0.1/my_custom_code.egg-info\n",
      "copying my_custom_code.egg-info/dependency_links.txt -> my_custom_code-0.1/my_custom_code.egg-info\n",
      "copying my_custom_code.egg-info/top_level.txt -> my_custom_code-0.1/my_custom_code.egg-info\n",
      "Writing my_custom_code-0.1/setup.cfg\n",
      "creating dist\n",
      "Creating tar archive\n",
      "removing 'my_custom_code-0.1' (and everything under it)\n"
     ]
    }
   ],
   "source": [
    "! python setup.py sdist --formats=gztar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying file://./dist/my_custom_code-0.1.tar.gz [Content-Type=application/x-tar]...\n",
      "/ [1 files][  1.3 KiB/  1.3 KiB]                                                \n",
      "Operation completed over 1 objects/1.3 KiB.                                      \n",
      "Copying file://model.joblib [Content-Type=application/octet-stream]...\n",
      "Copying file://preprocessor.pkl [Content-Type=application/octet-stream]...      \n",
      "/ [2 files][  8.4 KiB/  8.4 KiB]                                                \n",
      "Operation completed over 2 objects/8.4 KiB.                                      \n"
     ]
    }
   ],
   "source": [
    "# Upload model artifacts and custom code to Cloud Storage\n",
    "# model.joblib (model artifact)\n",
    "# preprocessor.pkl (model artifact)\n",
    "# my_custom_code-0.1.tar.gz (custom code)\n",
    "\n",
    "! gsutil cp ./dist/my_custom_code-0.1.tar.gz gs://$BUCKET_NAME/custom_prediction_routine/my_custom_code-0.1.tar.gz\n",
    "! gsutil cp model.joblib preprocessor.pkl gs://$BUCKET_NAME/custom_prediction_routine/model/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'CPR_test'\n",
    "VERSION_NAME = 'v1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created ml engine model [projects/qwiklabs-gcp-01-c2d37df448e7/models/CPR_test].\n"
     ]
    }
   ],
   "source": [
    "# create your model\n",
    "\n",
    "! gcloud ai-platform models create $MODEL_NAME \\\n",
    "  --regions $REGION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating version (this might take a few minutes)......done.                    \n"
     ]
    }
   ],
   "source": [
    "# --quiet automatically installs the beta component if it isn't already installed \n",
    "! gcloud --quiet beta ai-platform versions create $VERSION_NAME \\\n",
    "  --model $MODEL_NAME \\\n",
    "  --runtime-version 1.15 \\\n",
    "  --python-version 3.7 \\\n",
    "  --origin gs://$BUCKET_NAME/custom_prediction_routine/model/ \\\n",
    "  --package-uris gs://$BUCKET_NAME/custom_prediction_routine/my_custom_code-0.1.tar.gz \\\n",
    "  --prediction-class predictor.MyPredictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install --upgrade google-api-python-client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import googleapiclient.discovery\n",
    "\n",
    "instances = [\n",
    "  [6.7, 3.1, 4.7, 1.5],\n",
    "  [4.6, 3.1, 1.5, 0.2],\n",
    "]\n",
    "\n",
    "service = googleapiclient.discovery.build('ml', 'v1')\n",
    "name = 'projects/{}/models/{}/versions/{}'.format(PROJECT_ID, MODEL_NAME, VERSION_NAME)\n",
    "\n",
    "response = service.projects().predict(\n",
    "    name=name,\n",
    "    body={'instances': instances}\n",
    ").execute()\n",
    "\n",
    "if 'error' in response:\n",
    "    raise RuntimeError(response['error'])\n",
    "else:\n",
    "  print(response['predictions'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
